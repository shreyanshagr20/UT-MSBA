{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb3QnVJJbF-b"
      },
      "source": [
        "<b> MIS 382N: ADVANCED MACHINE LEARNING<b>\n",
        "\n",
        "Assignment 3\n",
        "\n",
        "Total points: 70\n",
        "\n",
        "Due: Monday, October 10 to be submitted via Canvas by 11:59 pm\n",
        "\n",
        "Your homework should be written in a python notebook. If you prefer, you can work in groups of two. **Please note that only one student per team needs to submit the assignment on Canvas but make sure to include both students' names and UT EIDs.**\n",
        "\n",
        "For any question that requires a handwritten solution, you may upload scanned images of your solution in the notebook or attach them to the assignment . You may write your solution using markdown as well.\n",
        "\n",
        "Please make sure your code runs and the graphs and figures are displayed in your notebook before submitting. (%matplotlib inline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkXOyWSCbMlw"
      },
      "source": [
        "**This can be an individual assignment or group of 2. If you choose to do it as a group, please specify who you are working with (name and EID), then only one student should submit the homework. Put your name and eid here.**\n",
        "\n",
        "Name:\n",
        "\n",
        "EID:\n",
        "\n",
        "Name:\n",
        "\n",
        "EID:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: Tensorflow Playground (20 pts)\n",
        "\n",
        "In this question, you will be playing with [Tensorflow Playground](https://playground.tensorflow.org).\n",
        "\n",
        "\n",
        "Select \"Classification\" as the Problem Type. Among the four datasets shown in DATA, please select the top left dataset.\n",
        "\n",
        "Use the following settings as the DEFAULT settings for all subquestions: Learning rate = 0.03, Activation = Tanh, Regularization = None, Ratio of training to test data = 50%, Noise = 0, Batch Size = 30, input as  ùëã1  with  ùëã2 , One hidden layer with 4 neurons.\n",
        "\n",
        "a) (4 pts) Use the DEFAULT setting and run two experiments - one using Tanh as the activation function and one using the Linear activation function. Report the train, test losses for both at the end of 1000 epochs. What qualitative difference do you observe in the decision boundaries obtained? What do you think is the reason for this?\n",
        "\n",
        "We will now study the effect of certain variations in the network structure or training process, keeping all other aspects the same as in the DEFAULT setting specified above, with Tanh as the activation.\n",
        "\n",
        "b) (4 pts) Effect of number of hidden units: Keep other settings the same as in DEFAULT, report the training loss and test loss at the end of 1000 epochs using 2 neurons and 8 neurons in the hidden layer. What do you observe in terms of the decision boundary obtained as the number of neurons increases? What do you think is the reason for this?\n",
        "\n",
        "c) (4 pts) Effect of Learning rate and number of epochs: Keep other settings the same as in DEFAULT. For learning rate 10, 1, 0.1, 0.01 and 0.0001, report the train, test losses at the end of 100 epochs, 500 epochs and 1000 epochs respectively. What do you observe from the change of loss vs learning rate, and the change of loss vs epoch numbers? Also report your observations on the training and test loss curve (observe if you see noise for certain learning rates and reason why this is happening).\n",
        "\n",
        "d) (4 pts) Effect of the number of layers: Change your activation to ReLU and use a single hidden layer with 4 neurons and then add another hidden layer with 3 neurons and train both your models for 1000 epochs. Comments on your final models and decision boundaries and observe your training and test loss curves as well.\n",
        "\n",
        "d) (4 pts) Use the DEFAULT setting. Play around with any hyperparameters, network architectures or input features (such as  sin(ùëã1),ùëã21  etc.), and report the best train and test loss you obtain (test loss should be no greater than 0.06). Attach the screenshot showing your full network, output and the parameters. Briefly justify your results, and comment on what helps/what doesn't help with lowering the loss, etc.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M4hCGuNQa6YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 : t-SNE (7 pts)\n",
        "\n",
        "Read this [article](https://erdem.pl/2020/04/t-sne-clearly-explained) on t-SNE, a dimensionality reduction technique for visualization and explain it in your own words in one or two paragraphs."
      ],
      "metadata": {
        "id": "tkIfStrtASfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer:"
      ],
      "metadata": {
        "id": "vMXiCKNHCDYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3: PCA (8 pts)\n",
        "\n",
        "Explain the principle of Principal Component Analysis algorithm and in what sense is the selection of the eigenvectors to represent the data is an optimal choice.  How do you reconstruct (a noisy version of) the original data from the eigenvectors and the loadings?\n",
        "\n"
      ],
      "metadata": {
        "id": "UHAjABOsAU1D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6pUQ7SvbU4G"
      },
      "source": [
        "#### Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYljtggnkSzl"
      },
      "source": [
        "# Question 4: Outlier detection using PyOD (20 pts)\n",
        "\n",
        "Outlier detection, or anomaly detection is usually an unsupervised learning task where the objective is to identify suspicious observations in data. It has been widely used in military surveillance for enemy activities to prevent attacks, intrusion detection in cyber security, fraud detection for credit cards, etc.\n",
        "\n",
        "PyOD is a comprehensive and scalable Python library for detecting outlying objects in multivariate data. PyOD includes more than 30 detection algorithms and provides unified APIs which makes it quite handy to use. In this question, you will play with PyOD, explore three different outlier detection algorithms and compare their performances. First let's install PyOD.\n",
        "\n",
        "```\n",
        "# install pyod using pip first\n",
        "!pip install pyod\n",
        "```\n",
        "\n",
        "You can load the data stored in 'Q3_train_dataset.csv' and 'Q3_test_dataset.csv' using the following codes.\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "# Load data code goes here\n",
        "train_df = pd.read_csv('Q3_train_dataset.csv')\n",
        "test_df = pd.read_csv('Q3_test_dataset.csv')\n",
        "\n",
        "X_train = train_df[['X_train_0', 'X_train_1', 'X_train_2', 'X_train_3', 'X_train_4']].to_numpy()\n",
        "y_train = train_df[['y_train']].to_numpy()\n",
        "X_test = test_df[['X_test_0', 'X_test_1', 'X_test_2', 'X_test_3', 'X_test_4']].to_numpy()\n",
        "y_test = test_df[['y_test']].to_numpy()\n",
        "```\n",
        "\n",
        " `X_train` and `X_test` contain the features, with the dimension of 5. `y_train` and `y_test` store the outlier labels, 0 means normal data, 1 means outlier data. \n",
        " \n",
        "a) **(5 pts)** **Fit `X_train` to a outlier detection model k Nearest Neighbors (kNN) using PyOD**, this [page](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.mcd) will provide some functions you may need. \n",
        "\n",
        "```\n",
        "from pyod.models.knn import KNN\n",
        "clf = KNN() # initialize KNN class using the default parameters\n",
        "\n",
        "# YOUR CODE SHOULD COME HERE, FIT THE MODEL USING X_TRAIN\n",
        "```\n",
        "**Use the fitted model to predict the outlier labels of `X_test`. Compute the raw outlier scores on `X_test` using `decision_function()`.**\n",
        "\n",
        "**Run PyOD's `evaluate_print()` function using the test set ground truth outlier labels and the raw outlier scores predicted by the model, to compute the ROC and Precision@n results .**\n",
        "\n",
        "```\n",
        "from pyod.utils.data import evaluate_print\n",
        "```\n",
        "\n",
        "b) **(5 pts)** `X_train` and `X_test` are 5-dimension features, which makes it impossible to visualize them in Euclidean plane. But we can use Principal Component Analysis (PCA) to reduce the dimensions of `X_train` and `X_test` to 2, and then plot them. You may want to use `fit_and_transform()` function.\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit pca to X_train and X_test and transform \n",
        "train_principalComponents = # IMPLEMENT\n",
        "test_principalComponents = # IMPLEMENT\n",
        "```\n",
        "\n",
        "After reducing the dimension to 2, now you can visualize the outliers using PyOD's `visualize()` function. Please plot the visualization. You may find [this](https://pyod.readthedocs.io/en/latest/pyod.utils.html#module-pyod.utils.example) useful on how to use `visualize()` .\n",
        "\n",
        "```\n",
        "from pyod.utils.example import visualize\n",
        "```\n",
        "\n",
        "Now you should be able to observe the ground truth outliers and the outliers predicted by the model.\n",
        "\n",
        "\n",
        "c) **(10 pts)** Apply the same process as in (a) and (b) to the following two models, and visualize the outlier results. Please compare the performance of the two models in terms of their ROC, Precision@n, and what you observe from the two visualizations.\n",
        "\n",
        "*   [Isolation-Based model - Isolation-based anomaly detection using Nearest-Neighbor Ensembles (INNE)](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.inne)\n",
        "\n",
        "```\n",
        "from pyod.models.inne import INNE\n",
        "```\n",
        "\n",
        "# Answer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use this code block if you are using Google Colab.\n",
        "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "from google.colab import files\n",
        "\n",
        "## It will prompt you to select a local file. Click on ‚ÄúChoose Files‚Äù then select and upload the file. \n",
        "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "F1-BTFNtBD-s",
        "outputId": "126b86e0-ccbb-42c4-e7d5-d69e46a93db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c270fb62-09db-4bbd-ba75-661aea461750\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c270fb62-09db-4bbd-ba75-661aea461750\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Q3_test_dataset.csv to Q3_test_dataset (1).csv\n",
            "Saving Q3_train_dataset.csv to Q3_train_dataset (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BULJ0M0sL1gf"
      },
      "source": [
        "# install pyod using pip first\n",
        "# !pip install pyod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEY5NClZL9a8"
      },
      "source": [
        "import pandas as pd\n",
        "# Load data code goes here\n",
        "train_df = pd.read_csv('Q3_train_dataset.csv')\n",
        "test_df = pd.read_csv('Q3_test_dataset.csv')\n",
        "\n",
        "X_train = train_df[['X_train_0', 'X_train_1', 'X_train_2', 'X_train_3', 'X_train_4']].to_numpy()\n",
        "y_train = train_df[['y_train']].to_numpy()\n",
        "X_test = test_df[['X_test_0', 'X_test_1', 'X_test_2', 'X_test_3', 'X_test_4']].to_numpy()\n",
        "y_test = test_df[['y_test']].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRPwxrFQL_Y3"
      },
      "source": [
        "# (a)\n",
        "from pyod.models.knn import KNN\n",
        "clf = KNN() # initialize KNN class using the default parameters\n",
        "\n",
        "# fit the model using X_train\n",
        "\n",
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwFvjZQ5MBE_"
      },
      "source": [
        "from pyod.utils.data import evaluate_print\n",
        "# predict the outlier labels of X_test using the trained model, compute the raw outlier scores on X_test using decision_function()\n",
        "# then use evaluate_print() to print out the evaluation results\n",
        "\n",
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIhWWz-MC1C"
      },
      "source": [
        "# (b)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit pca to X_train and X_test and transform \n",
        "train_principalComponents = # YOUR CODE SHOULD COME HERE\n",
        "test_principalComponents = # YOUR CODE SHOULD COME HERE\n",
        "\n",
        "from pyod.utils.example import visualize\n",
        "# Visualize the ground truth outliers and predicted outliers using visualize()\n",
        "\n",
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSs_Kej_MIN5"
      },
      "source": [
        "# (c)\n",
        "from pyod.models.inne import INNE\n",
        "\n",
        "\n",
        "# YOUR CODE SHOULD COME HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_NhQo4fMK0l"
      },
      "source": [
        "# Solutions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7LS1E520XPL"
      },
      "source": [
        "# Question 5: Pre-processing and sampling (15 pts)\n",
        "\n",
        "The following dataset contains House prices describing the sales of individual residential property in Ames, Iowa data with explanatory variables describing almost every aspect of residential homes and dependent variable being SalePrice. Here, some cells of most columns in the dataset contain NaN values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use this code block if you are using Google Colab.\n",
        "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "from google.colab import files\n",
        "\n",
        "## It will prompt you to select a local file. Click on ‚ÄúChoose Files‚Äù then select and upload the file. \n",
        "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "14_1eVTy9enN",
        "outputId": "702243ae-1e07-4ad5-9dc6-72598b1c4535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8d069e0-5332-4874-9b0f-676b22f2ea13\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8d069e0-5332-4874-9b0f-676b22f2ea13\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzXBJJihpKum"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import scipy.stats as stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(100)\n",
        "\n",
        "data = pd.read_csv(\"sales_data.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZpAfufgqDnc"
      },
      "source": [
        "a)**(2 pts)**Print the number of NaN, NULL and empty values (combined sum) in each column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZJ-OvcIO9bW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qX1tYc9PTeq"
      },
      "source": [
        "b)**(3 pts)**Create a copy of `data`, and name it `data_dm`, then create a new column in `data_dm` named `binned_garage_yr_built` and apply binning to the column `garage_yr_built`. Use `pandas.cut()` and modify its parameter list as below:\n",
        "\n",
        "```\n",
        "bins=[1900, 1930, 1960, 1990, 2020]\n",
        "labels=['1900-1930', '1930-1960', '1960-1990', '1990-2020']\n",
        "include_lowest=True\n",
        "```\n",
        "Next, perform one-hot encoding on this new column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5JLgp3ePXaH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fca0nB-KP5X8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZG-thPCPe8J"
      },
      "source": [
        "\n",
        "c)**(3 pts)**Drop the columns which have more than 90%, 95% and 98% of missing values. List the columns which get dropped in each of the cases and observe the number of columns that get dropped in each of the cases as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wwgOq-_PlXV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_Tj5rtPSLw"
      },
      "source": [
        "\n",
        "d)**(2 pts)**Take a sample of 800 rows at random and compute its mean. Compare the result with the population mean\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqijYNMkPS-a"
      },
      "source": [
        "np.random.seed(6)\n",
        "sample_ages = np.random.choice(a= data['SalePrice'], size=800)\n",
        "#Sample mean\n",
        "\n",
        "#Population mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FfEuB-hQ9a5"
      },
      "source": [
        "e) i)**(2pts)** Calculate 95% confidence intervals for SalePrice with a sample size of 100. \n",
        "\n",
        "ii)**(3pts)** Calculate 95 % confidence intervals for 100 different trials with a sample size of 500. Plot the confidence intervals and interpret how it captures the population mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrXDpIsgUhPs"
      },
      "source": [
        "np.random.seed(10)\n",
        "sample_size = 100\n",
        "sample = np.random.choice(a= data_dm['SalePrice'],\n",
        "                          size = sample_size)\n",
        "sample_mean = sample.mean()\n",
        "\n",
        "#Get the critical Z value\n",
        "\n",
        "\n",
        "#Get population standard deviation\n",
        "\n",
        "\n",
        "\n",
        "#margin of error\n",
        "margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size)) \n",
        "\n",
        "#confidence interval\n",
        "confidence_interval = (sample_mean - margin_of_error,\n",
        "                       sample_mean + margin_of_error)  \n",
        "\n",
        "#Print confidence interval and true mean value\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpX5NGr0VhyM"
      },
      "source": [
        "np.random.seed(12)\n",
        "\n",
        "#define the sample size\n",
        "\n",
        "intervals = []\n",
        "sample_means = []\n",
        "\n",
        "for sample in range(100):\n",
        "    sample = np.random.choice(a= data_dm['SalePrice'], size = sample_size)\n",
        "    sample_mean = sample.mean()\n",
        "    sample_means.append(sample_mean)\n",
        "    #compute z critical value\n",
        "\n",
        "    #compute population std dev        \n",
        "  \n",
        "    \n",
        "    margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))\n",
        "    confidence_interval = (sample_mean - margin_of_error,\n",
        "                           sample_mean + margin_of_error)  \n",
        "    \n",
        "    intervals.append(confidence_interval)\n",
        "    \n",
        "\n",
        "plt.figure(figsize=(13, 9))\n",
        "\n",
        "plt.errorbar(x=np.arange(0.1, 100, 1), \n",
        "             y=sample_means, \n",
        "             yerr=[(top-bot)/2 for top,bot in intervals],\n",
        "             fmt='o')\n",
        "\n",
        "plt.hlines(xmin=0, xmax=25,\n",
        "           y=data['SalePrice'].mean(), \n",
        "           linewidth=2.0,\n",
        "           color=\"red\")\n",
        "plt.title('Confidence Intervals for 100 Trials', fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXPziaA1P8Cl"
      },
      "source": [
        "### Solution:"
      ]
    }
  ]
}