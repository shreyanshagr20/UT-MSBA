---
title: "Supply Chain Assignment - Shreyansh Agrawal(sa55742)"
output:
  html_document:
    df_print: paged
---

------------------------------------------------------------------------

<center>

## Individual Assignment #1: ETS Laboratory

#### Due: Nov. 3 (Before Class)

#### (40 points)

</center>

------------------------------------------------------------------------

You have been hired by a company in the hospitality business to help them plan the staffing levels for the following year. The company operates resorts in three regions of the New South Wales of Australia; the three regions are the **Sydney**, the **South Coast** and the **North Coast NSW** areas.

As it takes time to hire new personnel and it is necessary for any new employee to undergo a detailed training program before starting to work, the company needs to plan its personnel requirements one year in advance. Furthermore, as it is possible for the company to transfer qualified personnel between regions, they are interested only in an aggregate forecast of their demand

As the company caters to **Holiday** travelers, and it has been growing faster than the market (i.e., it has been gaining market share), the Chief Commercial Officer estimates that next year they will have respectively (3%, 4%, 4%) of only the **Holiday** travelers in the (**Sydney**, **South Coast**, and **North Coast NSW**) regions respectively. Furthermore based on prior experience they anticipate that each traveler will stay respectively (5,2,2) hotel-nights in (**Sydney**, **South Coast**, and **North Coast NSW**) respectively

To forecast demand in hotel-nights use the **tourism** data set in **fpp3**. This data set reports the quarterly trips (in thousands) to different destinations, and as this data set has a *tsibble* structure, you can use **tidyverse** functions to subset the time-series of interest.

For the purposes of this assignment ignore all data before **2008 Q1** and use the data from **2008 Q1** through **2016 Q4** as a training set and the four quarters of **2017** as a testing set.

If you need to dust-off the tidyverse functions, a good reference is the electronic book [*R for Data Science*](https://r4ds.had.co.nz/) or alternatively, if you only need a quick refresher of the **dplyr** and **tidyr** functions you can use the following [*Data Wrangling Cheat Sheet*](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

### Part I. Model-Aggregation Forecast

#### Q1. After sub-setting for the time-series of interest in the **tourism** data set (a *tsibble*), add to the restricted set the corresponding demand time-series, by creating a column called *Demand* for each of the corresponding regions of interest. The *Demand* column should contain the hotel-nights (in thousands) corresponding to each of the *Trips* observations. After creating the *Demand* column, the code below uses the **group_by()** function to aggregate demand across regions creating the *AGG.D* column with the total demand and you are asked to find the best **ETS** model for each *Demand* time-series. In addition to the automatic fit, one of your colleagues suggest that you should find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend, as the automatic selection is based only on the AICc criterion, and the models with trend may be better under the *BIC* criterion. Report the best model as well as the corresponding *AICc* and *BIC*. What is the best model according to the information criteria?

```{r}
library(fpp3)

# Subset the appropriate data and create the "Demand" time-series
tourism %>% 
  filter(Quarter >= yearquarter("2008 Q1")) %>%
  filter(Purpose == "Holiday" & State == "New South Wales") %>%
  filter(Region %in% c("North Coast NSW","South Coast","Sydney")) %>%
  mutate(Demand = case_when(
    Region == "Sydney" ~ 0.03*Trips*5,
    Region == "South Coast" ~ 0.04*Trips*2,
    Region == "North Coast NSW" ~ 0.04*Trips*2
  )) -> D

D %>%
  group_by() %>%
  summarize(AGG.D = sum(Demand)) -> AD


# Break into Training and Testing sets.

ADTR <- AD %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
ADTE <- AD %>% 
  filter(Quarter >= yearquarter("2017 Q1"))
```

```{r}
f_aggr <- ADTR %>% 
           model(auto = ETS(AGG.D),
           ZAZ = ETS(AGG.D ~ trend("A")), 
           ZAdZ= ETS(AGG.D ~ trend("Ad")))

f_aggr %>% glance()
f_aggr %>% select(auto) %>% report()


```

-   ***Auto ETS (A,N,A)*** is the best model for aggregate data having following values:

    -   AICc - 310.86

    -   BIC - 317.95

-   The best model with Additive trend is ***ETS (A,A,A)***

-   The best model with Additive-damped trend is ***ETS (A,Ad,A)***

#### Q2. Now calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the three models fitted in (1).

-   In-sample (training) and the out-of-sample (testing) metrics for each of the three models fitted is:

```{r}

fc_aggr <- f_aggr %>% forecast(h = 4)

rbind(f_aggr %>% accuracy(), 
     fc_aggr %>% accuracy(data = ADTE))
```

#### Q3. Using the model with the lowest out-of-sample *MAPE*, and using all data (i.e., the *AD* dataset) prepare a forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence intervals.

-   ***Additive trend- ZAZ*** has the lowest out-of-sample MAPE for aggregated data and hence 2018 quarter sales will be forcasted using this model

```{r}

f_aggr_aug <- f_aggr %>% augment()

f_aggr_aug1 <- f_aggr_aug %>% filter(.model == "ZAZ")

fc_aggr <- f_aggr %>% forecast(h = 4)

f_aggr_aug1 %>% autoplot(.vars = AGG.D, col = "black") + geom_point(data = f_aggr_aug1, mapping = aes(y = .fitted))

fc_aggr %>% filter(.model == "ZAZ") %>% autoplot(ADTR) +
         geom_point(data = f_aggr_aug1, mapping = aes(y = .fitted), col = "blue") +
           geom_point(data = ADTE, mapping = aes(y = AGG.D), col = "red")
```

-   The 80% and 95% confidence intervals are:

```{r}

f_final <- AD %>%  
  model(m.AAA = ETS(AGG.D ~ error("A")+trend("A")+season("A")))  
  
fc_final <- f_final %>% 
  forecast(h = 4)

fc_final %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")
  
```

#### Q4. As in the hospitality business it is very costly to be short of personnel and your brand gets degraded when demand exceeds staffing capacity, we need to plan the staffing levels for each quarter according to a forecast of demand that we anticipate it will not be exceeded with a probability of 99%. What are these four quarterly demand levels?

-   The four quarterly demand levels are shown below:

```{r}
fc_final %>% mutate(Q99 = quantile(AGG.D, 0.99))
```

### Part II. Infrastructure Capacity Planning Forecast

As the resort infrastructure (e.g., buildings) and its direct fixed expenses cannot be moved across regions, it is important to carefully select the levels of capacity we should build in each region. To accomplish this we must forecast demand individually for each region, and then quantify the anticipated levels of occupation and the downside operational risk for each region.

#### Q5. Use the region-specific training and testing data (see code box below) and automatically select the ETS model that minimizes *AICc*, and as your colleague suggested also find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend as they may be preferred under the *BIC* criterion. Your *mable* should have 9 models in all; three models for each of the three regions. Report for each of the three models the corresponding *AICc* and *BIC* for each region. What is the ETS-name of the best model for each region according to the *AICc* information criterion? What is the best model for each region according to the *BIC* information criterion?

```{r}
# Break Region-Specific data into Training and Testing sets.
DTR <- D %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
DTE <- D %>% 
  filter(Quarter >= yearquarter("2017 Q1"))
```

```{r}

#Filtering out region-wise data from training and testing data set

DTR_North <- DTR %>% 
  filter(Region == "North Coast NSW")

DTE_North <- DTE %>% 
  filter(Region == "North Coast NSW")

DTR_South <- DTR %>% 
  filter(Region == "South Coast")

DTE_South <- DTE %>% 
  filter(Region == "South Coast")

DTR_Sydney <- DTR %>% 
  filter(Region == "Sydney")

DTE_Sydney <- DTE %>% 
  filter(Region == "Sydney")
```

-   Please find below mable having all the 9 models:

```{r}
f_overall <- DTR %>% 
      model(auto = ETS(Demand),
           ZAZ = ETS(Demand ~ trend("A")), 
           ZAdZ= ETS(Demand ~ trend("Ad")))

f_overall %>% glance()   
fc_overall <- f_overall %>% forecast(h = 4)
f_1 <- DTR %>% model(auto = ETS(Demand))
```

-   Best model for the region is ***ETS(M,N,M)*** as per both AICc and BIC - for region North Coast NSW

-   Best model for the region is ***ETS(M,N,M)*** as per both AICc and BIC - for region South Coast

-   Best model for the region is ***ETS(A,N,A)*** as per both AICc and BIC - for region Sydney

#### Q6. Calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the nine models fitted in (5). Sometimes the damped models can introduce a bias in forecasting horizons longer than one or two periods. Is this a concern for the "AAdM"model for any of the three regions? Explain. Using for each region the model with the lowest *BIC*, and using all data (i.e., the *D* dataset) prepare a region-specific forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence interval

-   The in-sample (training) and the out-of-sample (testing) metrics for each of the nine models is:

```{r}

f_c <- f_overall %>% forecast(h=4) 
rbind(f_overall %>% accuracy(), f_c %>% accuracy(data = DTE))

```

-   We can see there is bias existing for the ***'AAdM'*** model which is clearly visible from the below plotted graphs. The bias is usually existing post the second period

    -   In Sydney, there is a high bias

    -   In North Coast NSW, there is very little bias

    -   In South Coast, there is no bias

```{r}

f_reg = f_overall %>%  augment() 

f_reg %>% autoplot(.vars = Demand, col = "black") + 
  geom_point(data = f_reg, mapping = aes(y = .fitted))

fc_reg = f_overall %>% forecast(h = 4)

fc_reg %>% autoplot(DTR) +
          geom_point(data = f_reg, mapping = aes(y = .fitted), col = "blue") +
          geom_point(data = DTE, mapping = aes(y = Demand), col = "red")
```

-    The best model according to BIC information criterion is

    -   North Coast NSW is ETS(M,N,M)

    -   South Coast is ETS(M,N,M)

    -   Sydney is ETS(A,N,A)

#### North Coast NSW region

```{r}

f_North_aug <- D %>% 
  filter(Region == "North Coast NSW") %>%  
  model(auto = ETS(Demand ~ error("M")+trend("N")+season("M")))  
  
fc_North_full <- f_North_aug %>% forecast(h = 4)

fc_North_full %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")
```

#### South Coast Region

```{r}

f_South_aug <- D %>% 
  filter(Region == "South Coast") %>%  
  model(auto = ETS(Demand ~ error("M")+trend("N")+season("M")))  
  
fc_South_full <- f_South_aug %>% forecast(h = 4)

fc_South_full %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")
```

#### Sydney Region

```{r}

f_Sydney_aug <- D %>% 
  filter(Region == "Sydney") %>%  
  model(auto = ETS(Demand ~ error("A")+trend("N")+season("A")))  
  
fc_Sydney_full <- f_Sydney_aug %>% forecast(h = 4)

fc_Sydney_full %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")

```

#### Q7. In infrastructure (buildings, etc) cannot be modified from quarter to quarter, we must plan for capacity level for the entire year in each of the three regions. As with personnel, management thinks it is too expensive to be out of capacity to satisfy demand, and have proposed to build enough capacity to satisfy all demand of the highest season with a probability of 98%. What is the constant quarterly capacity that they should build in each region? If we define the mean-forecast occupancy rate as the occupancy rate implied by the mean forecast, prepare a table showing the mean-forecast occupancy rate for each of the four quarters at each of the three regions.

-   The constant quarterly capacity is calculated by using the maximum quarterly capacity for each of the region as shown below:

```{r}

g_North_2018 <- fc_North_full %>% mutate(Q98 = quantile(Demand, 0.98)) 

cat('The constant quarterly capacity build in North Coast NSW region is :: ')
constant_quarterly_capacity_North=max(g_North_2018$Q98)
constant_quarterly_capacity_North
```

```{r}

g_South_2018 <- fc_South_full %>% mutate(Q98 = quantile(Demand, 0.98))

cat('The constant quarterly capacity in South Coast region is :: ')
constant_quarterly_capacity_South=max(g_South_2018$Q98)
constant_quarterly_capacity_South
```

```{r}

g_Sydney_2018 <- fc_Sydney_full %>% mutate(Q98 = quantile(Demand, 0.98))  

cat('The constant quarterly capacity in Sydney region is :: ')
constant_quarterly_capacity_Sydney=max(g_Sydney_2018$Q98)
constant_quarterly_capacity_Sydney
```

-   The mean-forecast occupancy rate for each region is:

```{r}

g_North_2018$ constant_quarterly_capacity = constant_quarterly_capacity_North
g_South_2018$ constant_quarterly_capacity = constant_quarterly_capacity_South
g_Sydney_2018$ constant_quarterly_capacity = constant_quarterly_capacity_Sydney

m_overall <- rbind(g_North_2018,g_South_2018,g_Sydney_2018) %>% as_tibble
m_overall$mean_forecast_occupancy = m_overall$`.mean`/m_overall$constant_quarterly_capacity

m_overall %>% select(Region,Quarter,`.mean`,constant_quarterly_capacity,mean_forecast_occupancy)
```

#### Q8. Another metric of interest is the 10%-down-side occupancy risk. This will be measured as the occupancy rate that would be obtained if actual demand is at the low 10% of the probability distribution of its forecast. What is the 10% level of the forecast probability distribution for each quarter at each region. Prepare also a table showing the 10%-downside-occupancy for each quarter at each region.

-   The 10% downside-occupancy level of the forecast probability distribution and occupancy rate for each quarter at each region is:

```{r}

m_overall %>% mutate(Q10 = quantile(Demand, 0.10)) %>% select(Region, State, Quarter, Demand, constant_quarterly_capacity, Q10)  %>% mutate(occupancy_rate = Q10/constant_quarterly_capacity)

```
