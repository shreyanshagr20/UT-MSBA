---
Title: 'Individual Assignment 3: Shreyansh Agrawal (sa55742)"'
output:
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------

<center>

### Embedding a Demand Function into an ARIMA Model:

### Regression with ARIMA Errors Laboratory.

#### (Total 40 pts.)

#### Due: Dec. 5

</center>

------------------------------------------------------------------------

The sales data is provided in CSV format in the file **"PBS.csv"**. As
this is an individual skill-building assignment (as opposed to an
open-ended team assignment), and I would like to achieve some degree of
convergence in your answers, hence I have provided a common data
preprocessing script below. The data set corresponds to the total weekly
sales of peanut butter for a supermarket chain, not for the individual
stores. As you can observe from the file, the data corresponds to a
combination of multiple brands as well as the supermarket private label
(generic) in sizes ranging from 0.75 to 1.5 lbs.

The data includes the following information for each individual stock
keeping unit (SKU) as identified by its UPC code on each week in the
data file:

-   VEND Number identifying the product vendor (48001 corresponds to
    Unilever).
-   UPC The product's universal product code (bar code)
-   UNITS Sales volume
-   DOLLARS Dollar sales revenue
-   VOL_EQ Weight in pounds of a units sold
-   PPU Price per unit (\$/lb)
-   F Factor specifying advertising in the store weekly flyer:
    -   F = "A+" Large size ad.
    -   F = "A" Medium size ad.
    -   F = "B" Small size ad.
-   D Factor specifying In-Store Display
    -   D = 0 No In-Store Display
    -   D = 1 In-Store Display

To simplify the modeling process (and the assignment) in the
preprocessing script below I lumped all products into just three
aggregate products (sub-categories): "SK" includes all Skippy brand
products, "OB" includes all other branded products and "PL" includes all
private label products. For each of the three aggregate products I
obtained the total sales (volume) in pounds, the average sale prices
(\$/lb), and volume-weighted averages of the advertising and display
variables (F and D). Please take a few minutes to examine the
pre-processing script below.

Our goal is to embed a log-log demand model in an ARIMA model
(Regression with ARIMA errors) that accounts for the auto-correlations
in the sales data. As a first attempt we would like to include a demand
function of the following form:

$$y=e^{βx} p_S^α p_B^γ p_P^{γ_o}$$

Where the model variables and parameters are defined as follows:

-   $y$ : Demand (sales volume)
-   $p_S$ : Average price per pound of "Skippy" products
-   $p_B$ : Average price per pound of "Other Branded" products
-   $p_P$ : Average price per pound of "Private Label" products
-   $x$ : Vector of weighted averages of advertising and display
    variables for each product sub-category
-   $β$ : Vector of coefficients for advertising and display variables
-   $α,γ,γ_o$: Coefficients (elasticity and cross-elasticities) of
    prices

We have a total of 104 weeks of data. In this assignment we will use
weeks 1 through 94 as a training set and weeks 95 through 104 as a
testing set.

```{r, message=FALSE, warning=FALSE}
library(fpp3)
library(reshape2)
library(glmnet)
library(coefplot)
library(lubridate)
rm(list=ls())

# Data Pre-Processing 
#
PBS <- read.csv("PBS.csv") %>% 
  mutate( F_LSA=ifelse(F=="A+",1,0),      # Large Size Ad Dummy
          F_MSA=ifelse(F=="A",1,0),       # Medium Size Ad Dummy
          F_SSA=ifelse(F=="B",1,0)) %>%   # Small Size Ad Dummy
  # Promotional variables are weighted by sales volume (oz)
  mutate(S_LB = UNITS * VOL_EQ,
         WF_LSA = F_LSA * S_LB,     # Large Size Ad Weighted
         WF_MSA = F_MSA * S_LB,     # Medium Size Ad Weighted
         WF_SSA = F_SSA * S_LB,     # Small Size Ad Weighted
         WD     = D * S_LB) %>%     # In-Store Display Weighted

  mutate(VEND =ifelse(VEND == 48001,"SK",ifelse( VEND == 99998,"PL","OB"))) %>%
  select(-F)

# Create aggregate variables by product-week
x.pw <- PBS %>% group_by(WEEK, VEND) %>% 
  summarise(S.DOLLARS = sum(DOLLARS),      # Total $ Sales 
            S.S_LB    = sum(S_LB),         # Total L. Sales
            S.WF_LSA  = sum(WF_LSA),       # Total Weighted Large Ad
            S.WF_MSA  = sum(WF_MSA),       # Total Weighted Medium Ad
            S.WF_SSA  = sum(WF_SSA),       # Total Weighted Small Ad
            S.WD      = sum(WD)) %>%       # Total Weighted Store Disp
  # Calculate weigted averages of Advertising and Promotion variables
  mutate(A.PPU = log(S.DOLLARS / S.S_LB),  # Log of Avg. Price ($/pound)
         S.WF_LSA  = S.WF_LSA / S.S_LB,    # Avg. Weighted Large Ad
         S.WF_MSA  = S.WF_MSA / S.S_LB,    # Avg. Weighted Medium Ad
         S.WF_SSA  = S.WF_SSA / S.S_LB,    # Avg. Weighted Small Ad
         S.WD      = S.WD / S.S_LB)        # Avg. Weighted Store Disp

#
x.pw <- x.pw %>%
  mutate(LS  = log(S.S_LB)) %>% 
  select(-S.DOLLARS, -S.S_LB)
#
# Creeate separate dataframes for each brand group
x.SK <- x.pw %>% filter(VEND == "SK") %>% select(-VEND)
colnames(x.SK) <- c("WEEK","WF_LSA.SK","WF_MSA.SK","WF_SSA.SK","S.WD.SK","PPU.SK","LS.SK" )
x.OB <- x.pw %>% filter(VEND == "OB") %>% select(-VEND,-LS)
colnames(x.OB) <- c("WEEK","WF_LSA.OB","WF_MSA.OB","WF_SSA.OB","S.WD.OB","PPU.OB")
x.PL <- x.pw %>% filter(VEND == "PL") %>% select(-VEND,-LS)
colnames(x.PL) <- c("WEEK","WF_LSA.PL","WF_MSA.PL","WF_SSA.PL","S.WD.PL","PPU.PL")

#Join the product-specific dataframes to create an expanded dataframe for SK using the 
# data from competing products as additional columns to be used as predicitve variables

xmat <- x.SK %>%
  left_join(x.OB,by="WEEK") %>%
  left_join(x.PL,by="WEEK")

# If your code executed correctly xmat should have 17 cols and 104 rows.
#
xm <- model.matrix(LS.SK ~(. - WEEK)^2 , data=xmat)[,-1]
y <- xmat$LS.SK

#Separation of Training and Testing sets
xm.tr <- xm[1:94,]
y.tr <-  y[1:94]
xm.te <- xm[95:104,]
y.te <-  y[95:104]
#
```

### Ques 1: (5 pts) After pre-processing the data, notice that you have 120 predictive variables plus the sales vector. Notice that the pre-processing step already computes the log of the average prices and sales volumes. Now use The Lasso on the training set to obtain (a) a regularized model and (b) the reduced set of predictive variables that minimize the cross-validated MSE over the training set (i.e., the set of variables included in the Lasso-regularized model). (Use set.seed(1) before 10-fold cross-validation). Report the coefficients of the regularized model.

**Ans 1:**

**(a) LASSO regularized model:**

```{r, message=FALSE, warning=FALSE}

set.seed(1)
#cross-validation using k=10
lasso = cv.glmnet(xm.tr, y.tr, alpha=1 ,k = 10)

#finding optimal lambda when the MSE is lowest
lambda = lasso$lambda.min
cat("The optimal value of lambda when MSE is lowest is: ", lambda)

#plotting the MSE vs lambda 
plot(lasso) 
```

**(b) The reduced set of predictive variables:**

```{r, message=FALSE, warning=FALSE}

# non-zero coefficients
lasso_best= glmnet(xm.tr, y.tr, alpha=1, lambda = lambda)
non_zero_coef = coef(lasso_best)
cat("Non-zero coefficients:\n")
print(non_zero_coef[non_zero_coef[,1]!=0,])
```

### Ques 2: (5 pts) Use the training set to fit an unrestricted regression model (i.e., **lm(...)** ) on the reduced set of explanatory variables identified by The Lasso. Report the coefficients of the full model and comment on the fit of the model and examine the auto-correlations of the residuals of this model.

**Ans 2:**

```{r, message=FALSE, warning=FALSE}

#unrestricted model

unrest_lasso = lm(y.tr ~ xm.tr[,"PPU.SK"]+xm.tr[,"WF_LSA.SK:PPU.OB"]+xm.tr[,"S.WD.SK:PPU.OB"]+xm.tr[,"S.WD.SK:PPU.PL"])

#printing model 
print(unrest_lasso)

#printing summary
summary(unrest_lasso)
```

```{r, message=FALSE, warning=FALSE}

# checking autocorrelation
acf(resid(unrest_lasso))

lasso_resi = unrest_lasso$res
length = length(lasso_resi) 
resi = lm(lasso_resi[-length] ~ lasso_resi[-1]) 
summary(resi)
```

As visible from acf and summary, the auto-correlations exists between
residuals. At lag 0, there is correlation of 1 and at lag 1 of 0.3

### Ques 3: (5 pts) Reorganize the data as a **tsibble** and the use the **ARIMA()** function to fit a simple ARIMA model (not a regression with ARIMA errors model) to explain the training set log-of-sales-volume data. Report the diagnostic of your model's residuals and comment on the model's validity.

**Ans 3:**

```{r, message=FALSE, warning=FALSE}

#splitting into training and testing set
xmat.tr = xmat[1:94,]
xmat.te = xmat[95:104,]

#tssible
ARIMA_tr = xmat.tr %>% as_tsibble(index=WEEK)

ARIMA_te = xmat.te %>% as_tsibble(index=WEEK)

#fit ARIMA Model
ARIMA_fit = ARIMA_tr %>% model(model_ARIMA = ARIMA(LS.SK))

ARIMA_fit %>% glance()

ARIMA_fit %>% report()

ARIMA_fit  %>%  gg_tsresiduals()

```

```{r}

#performing ljung_box test
ARIMA_fit %>% 
  augment() %>%
  features(.resid, ljung_box)

```

As visible from acf, the auto-correlations does not exist between
residuals. This is also confirmed by *ljung box* where lb_pvalue is
\~0.97. [**This is a valid model**]{.underline}

### Ques 4: (5 pts) Use the model in Question 3 to prepare a 10 period ahead forecast and compare it (overly it) with the testing set log-of-sales data. Comment on the usefulness of this model in terms of precision and confidence interval.

**Ans 4:**

```{r, message=FALSE, warning=FALSE}
for_mod_1 = ARIMA_fit %>% forecast(h=10)

fit_mod_1 = ARIMA_fit %>%  augment() 

rbind(for_mod_1 %>% accuracy(data = ARIMA_te), ARIMA_fit %>% accuracy())

for_mod_1 %>% autoplot(ARIMA_tr) +
          geom_point(data = fit_mod_1, mapping = aes(y = .fitted), col = "green") +
          geom_point(data = ARIMA_te, mapping = aes(y = LS.SK), col = "blue")

for_mod_1 %>% hilo(level =95) %>% unpack_hilo("95%") %>% mutate(Actual = ARIMA_te$LS.SK)
```

[**This is a valid model.**]{.underline} Even though the RMSE and MAE on
the test data is very low the forecast is not great because there is a
wide spread between upper and lower confidence level. Hence, it will not
accurately predict the forecast

### Ques 5: (5 pts) Use the **ARIMA()** function to automatically fit a regression with ARIMA errors model to explain sales data (log) using only the predictive variables identified by The Lasso in Question 1. Examine the model's residuals and comment on its validity.

**Ans 5:** The predictive variables from the LASSO from Question 1 are:
PPU.SK, WF_LSA.SK:PPU.OB, S.WD.SK:PPU.OB and S.WD.SK:PPU.PL

```{r, message=FALSE, warning=FALSE}

#Model with best lasso variables
fit_mod_2 = ARIMA_tr %>% model(model_2 = ARIMA(LS.SK ~ PPU.SK + WF_LSA.SK:PPU.OB + S.WD.SK:PPU.OB + S.WD.SK:PPU.PL))

#printing summary and coefficients
fit_mod_2 %>% glance()

fit_mod_2 %>% report()

fit_mod_2  %>%  gg_tsresiduals()

```

```{r, message=FALSE, warning=FALSE}
#performing ljung_box test
fit_mod_2 %>% 
  augment() %>%
  features(.resid, ljung_box)
```

```{r, message=FALSE, warning=FALSE}
acf(resid(fit_mod_2))
```

As visible from acf, the auto-correlations does not exist between
residuals. This is also confirmed by *ljung box* where lb_pvalue is
\~0.89. [**This is a valid model**]{.underline}

### Ques 6: (5 pts) Obtain a regression with ARIMA errors model that improves on the automatically selected model in Question 5 in terms of its information coefficients and residual diagnostics. Compare the coefficients of the explanatory variables in (a) The Lasso model, (b) The unrestricted model obtained in Question 2, and (c) The ones obtained in this question. Then use the B notation (polynomial) to describe the model you obtained.

**Ans 6:** As automatic selection, we get best model with pdq(0,1,2) in
the above question. However, from PACF, it is visible that at lag 3, the
residuals are significant. So, we will be fitting the ARIMA model now
with **pdq(3,1,2)**

```{r, message=FALSE, warning=FALSE}

fit_mod_2 %>%  residuals(type="regression") %>% 
  gg_tsdisplay(difference(.resid), "partial", lag_max = 16)
```

```{r, message=FALSE, warning=FALSE}

#pdq(3,1,2)
fit_mod_3 = ARIMA_tr %>% model(mod_3 = ARIMA(LS.SK ~ PPU.SK + WF_LSA.SK:PPU.OB + S.WD.SK:PPU.OB + S.WD.SK:PPU.PL +pdq(3,1,2)))

#printing summary and coefficients
fit_mod_3 %>% glance()

fit_mod_3 %>% report()

fit_mod_3

fit_mod_3 %>%  residuals(type="regression") %>% 
  gg_tsdisplay(difference(.resid), "partial", lag_max = 16)

```

```{r, message=FALSE, warning=FALSE}
# performing ljung_box test
fit_mod_3 %>% augment() %>%features(.resid, ljung_box)

```

```{r, message=FALSE, warning=FALSE}
acf(resid(fit_mod_3))
```

As visible from acf, the auto-correlations does not exist between
residuals. When we move model from pdf(0,1,2) to pdf(3,1,2), the value
of p-value updates from 0.89 to 0.96

**Comparing 3 models:**

```{r, message=FALSE, warning=FALSE}

three_models =data.frame(coef(lasso_best)[coef(lasso_best)[,1]!=0,][2:5], unrest_lasso$coefficients[2:5],coef(fit_mod_3)$estimate[6:9],coef(fit_mod_2)$estimate[3:6])
colnames(three_models) <- c('Lasso','MLR','ARIMA (3,1,2)','ARIMA (0,1,2)')
three_models

```

**B notation:**

$$(1-B)(LS.SK)_t = -2.6636(1-B)(PPU.SK)+0.2743(1-B)(WF\_LSA.SK\_PPU.OB)-0.36(1-B)(S.WD.SK\_PPU.OB)+0.7737(1-B)(S.WD.SK\_PPU.PL)+(1-B)n_t$$

$$(1+0.2144B+0.4667B^2+0.343B^3)(1-B)n_t = (1+0.2937B+0.439B^2)e_t$$

### Ques 7: (5 pts) Use the model in Question 5 to prepare a 10 period ahead forecast and compare it (overlay it) with the testing set log-of-sales data. You can also obtain the values of the regressors used in the forecasting model from the testing data set **xm.te**. Comment on the usefulness of this model in terms of precision and confidence interval relative to the model without explanatory variables in Question 3.

**Ans 7:**

```{r, message=FALSE, warning=FALSE}

for_mod_3 = fit_mod_3 %>% forecast(new_data = ARIMA_te)

fit_mod = fit_mod_3 %>% augment()

for_mod_3 %>% autoplot(ARIMA_tr) +
          geom_point(data = fit_mod, mapping = aes(y = .fitted), col = "green") +
          geom_point(data = ARIMA_te, mapping = aes(y = LS.SK), col = "blue")

rbind(for_mod_3 %>% accuracy(data = ARIMA_te), fit_mod_3 %>% accuracy())

for_mod_3 %>% hilo(level =95) %>% unpack_hilo("95%") %>% mutate(Actual = ARIMA_te$LS.SK)

```

[**This is a valid model.**]{.underline} There is not a wide spread
between upper and lower confidence level. Hence, it will accurately
predict the forecast. The forecasts will be better than the only ARIMA
fit. Moreover, the accuracy metrics are better than only ARIMA fit. So,
ARIMA model with errors is better than only ARIMA model
