{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdfbeff",
   "metadata": {},
   "source": [
    "#   RM 294: Optimization Project 3 â€“ Non-Linear Programming\n",
    "\n",
    "## Group members: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a774fdc",
   "metadata": {},
   "source": [
    "| Group Member | UT EID |\n",
    "| ----------- | ----------- |\n",
    "| Manvi Goyal | mg65952 |\n",
    "| Shreyansh Agrawal | sa55742        |\n",
    "| Rianna Patel | rnp599        |\n",
    "| Nevin Arimilli | na24887        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b407e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\anaconda3\\envs\\ShreyanshConda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6eaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the files\n",
    "train_df= pd.read_csv('training_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# adding a column for intercept\n",
    "train_df.insert(1,column='X0',value=np.ones(len(train_df)))\n",
    "test_df.insert(1,column='X0',value=np.ones(len(test_df)))\n",
    "\n",
    "# defining feature space and target variable\n",
    "X_train = np.array(train_df.iloc[0:,1:])\n",
    "Y_train = np.array(train_df['y'])\n",
    "X_test = np.array(test_df.iloc[0:,1:])\n",
    "Y_test = np.array(test_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821ecc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_LIMIT  = 432 # time limit per iteration\n",
    "M = 100\n",
    "n_folds = 10\n",
    "\n",
    "#defining th evalues of k for which we want to run the folds\n",
    "k_list=np.linspace(5,50,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da449814",
   "metadata": {},
   "source": [
    "### We know that general form of the Quadratic Programming is:\n",
    "\n",
    "Objective Function: $min_x$ $x^{T}$Qx+ $c^{T}$x\n",
    "\n",
    "Constraints:\n",
    "1. Ax$\\leq$b\n",
    "2. x$\\geq$0\n",
    "\n",
    "#### In our case, below are values for implementing MIQP:\n",
    "\n",
    "Total Number of Decision Variables: *2m+1*\n",
    "\n",
    "   1. m+1 beta values -  $\\beta_0$, $\\beta_1$,...,$\\beta_m$\n",
    "   2. m binary variables - $z_1$,$z_2$,...,$z_m$\n",
    "   \n",
    "##### Objective function: \n",
    "$min_{\\beta,z}$ $\\beta^{T}$($X^{T}$X)$\\beta$+ (-2$y^{T}$X)$\\beta$\n",
    "    \n",
    "On comparing with Quadratic form, we know:\n",
    "\n",
    "   Q = $X^{T}$X and c = -2$y^{T}$X\n",
    "   \n",
    "Total number of Constraints = *2m+1*\n",
    "\n",
    "   1. $\\sum_{i=1}^{m} z_i$ $\\leq$ k --> 1 constraint\n",
    "   2. -$z_i$M $\\leq$ $\\beta_i$ *where i = 1,2,....,m* --> m constraints\n",
    "   3. $\\beta_i$ $\\geq$ $z_i$M  *where i = 1,2,....,m* --> m constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd916b",
   "metadata": {},
   "source": [
    "### MIQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6ae562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs the n folds for cross validation\n",
    "def gen_test_val_split(X_train, n_folds):\n",
    "    \n",
    "    n_elements = int(X_train.shape[0]/n_folds)\n",
    "    cv_list = []\n",
    "\n",
    "    a = np.arange(0,X_train.shape[0])\n",
    "    \n",
    "    for i in range(0,n_folds):\n",
    "        cv = np.random.choice(a,size=n_elements,replace=False)\n",
    "        cv_list.append(cv)\n",
    "        a = a[~np.isin(a,cv)]\n",
    "\n",
    "    return cv_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5de72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fucntion is used to optimise the miqp model based on the training data passed and returns the optimization model from which we can then extract the beta values \n",
    "\n",
    "def optimize_miqp(X,y,k,TIME_LIMIT,M):\n",
    "    \n",
    "    # number of rows\n",
    "    n = X.shape[0]\n",
    "    # number of variables\n",
    "    m = X.shape[1]-1\n",
    "\n",
    "    # Quadratic part Q\n",
    "    obj_quad= np.zeros((2*m+1, 2*m+1))\n",
    "    obj_quad[0:m+1,0:m+1] = X.T @ X\n",
    "        \n",
    "    # Linear Part C\n",
    "    obj_lin = np.zeros(2*m+1)\n",
    "    obj_lin[:(m+1)] = -2*y.T @ X\n",
    "        \n",
    "    # Defining the constraints\n",
    "\n",
    "    # Creating the A matrix\n",
    "    A = np.zeros((2*m+1, 2*m+1))\n",
    "    sense = ['']*A.shape[0]\n",
    "    b = np.zeros(2*m+1)\n",
    "    \n",
    "    # big M constraint: b_j <= Mz_j \n",
    "    np.fill_diagonal(A[:m, 1:m+1], 1) \n",
    "    np.fill_diagonal(A[:m, m+1:2*m+1], -M)  \n",
    "\n",
    "    # big M constraint: -Mz_j <= b_j\n",
    "    np.fill_diagonal(A[m:-1, 1:m+1], 1) \n",
    "    np.fill_diagonal(A[m:-1, m+1:2*m+1], M)\n",
    "\n",
    "    # Sum of the number of independent betas should be equal to k\n",
    "    A[-1, m+1:] = 1\n",
    "    sense = np.array(['<']*m + ['>']*m + ['<'])\n",
    "    lb = np.array([np.NINF]+[-M]*m+[np.NINF]*m)\n",
    "\n",
    "    b = np.concatenate((np.zeros(2*m), [k]))\n",
    "\n",
    "    opt_model = gp.Model()\n",
    "    opt_model_x = opt_model.addMVar(len(obj_quad),vtype=['C']*(m+1)+['B']*m, lb=lb) \n",
    "    opt_model_con = opt_model.addMConstrs(A, opt_model_x, sense, b)\n",
    "    opt_model.setMObjective(obj_quad, obj_lin, 0, sense=gp.GRB.MINIMIZE)\n",
    "    opt_model.Params.OutputFlag = 0\n",
    "    opt_model.Params.TimeLimit = TIME_LIMIT\n",
    "    opt_model.optimize()\n",
    "\n",
    "    return opt_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272adfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running 10-fold cross validation for different values of k\n",
    "\n",
    "X = np.array(train_df.iloc[0:,1:])\n",
    "y = np.array(train_df['y'])\n",
    "\n",
    "cv_index = gen_test_val_split(X_train, n_folds)\n",
    "a = np.arange(0,train_df.shape[1])\n",
    "\n",
    "# list to store mse and beta values for each iteration\n",
    "mse_list = []\n",
    "beta_list = []\n",
    "\n",
    "# dataframe to store the outputs of all th eietrations\n",
    "col_list = ['k','n_fold']\n",
    "col_list.extend(train_df.columns[1:])\n",
    "col_list.extend(['mse'])\n",
    "df_history = pd.DataFrame(columns=col_list)\n",
    "counter = 0\n",
    "\n",
    "for k in k_list:\n",
    "\n",
    "    for i in range(0,n_folds):\n",
    "        \n",
    "        X_val = X[cv_index[i]]\n",
    "        y_val = y[cv_index[i]]\n",
    "        X_train = X[a[~np.isin(a,cv_index[i])]]\n",
    "        y_train = y[a[~np.isin(a,cv_index[i])]]\n",
    "\n",
    "        model = optimize_miqp(X=X_train,y=y_train,k=k,TIME_LIMIT=TIME_LIMIT,M=M)\n",
    "\n",
    "        m=X_train.shape[1]-1\n",
    "        beta = np.array(model.X)[0:m+1]\n",
    "        beta_list.append(beta)\n",
    "\n",
    "        y_pred = X_val@beta\n",
    "        mse = mean_squared_error(y_pred, y_val)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "        row_arr = [k,i]\n",
    "        row_arr.extend(beta)\n",
    "        row_arr.extend([mse])\n",
    "\n",
    "        # storing to df\n",
    "        df_history.loc[counter] = row_arr\n",
    "\n",
    "        counter = counter+1\n",
    "\n",
    "# storing the outputs in a csv file for reproducibility\n",
    "df_history.to_csv(\"miqp_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the best k using miqp\n",
    "miqp_outputs = pd.read_csv(\"miqp_outputs.csv\")\n",
    "\n",
    "# note for the graph we have shown the total mse of all the folds - but i shouldn't matter if we show total mse or average mse since for each k we have 10 folds\n",
    "miqp_outputs[['k','mse']].groupby('k').sum().sort_values(ascending=True,by='mse').plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "miqp_outputs[['k','mse']].groupby('k').sum().sort_values(ascending=True,by='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6e334",
   "metadata": {},
   "source": [
    "From the above graph we can see that we get the lower cross validation error at k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8345a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining feature space and target variable\n",
    "X_train = np.array(train_df.iloc[0:,1:])\n",
    "Y_train = np.array(train_df['y'])\n",
    "X_test = np.array(test_df.iloc[0:,1:])\n",
    "Y_test = np.array(test_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d903bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_28712\\112114350.py:2: DeprecationWarning: Deprecated, use Model.addMConstr() instead\n",
      "  final_model = optimize_miqp(X=X_train,y=Y_train,k=10,TIME_LIMIT=6000,M=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is: 2.33654\n"
     ]
    }
   ],
   "source": [
    "# now retraining the model using the complete training data with k=10\n",
    "final_model = optimize_miqp(X=X_train,y=Y_train,k=10,TIME_LIMIT=6000,M=100)\n",
    "\n",
    "m=X_train.shape[1]-1\n",
    "\n",
    "# selcting the value of coefficients\n",
    "beta = np.array(final_model.X)[0:m+1]\n",
    "\n",
    "# predicting on test data\n",
    "y_pred = X_test@beta\n",
    "\n",
    "#mse = np.power(y_pred-Y_test,2).sum()\n",
    "print(\"The test error is: \"+ str(round(mean_squared_error(Y_test, y_pred),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb74f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for report purposes\n",
    "df_beta = pd.DataFrame(beta)\n",
    "df_beta.to_csv(\"miqp_beta_10.csv\")\n",
    "\n",
    "df_y_pred = pd.DataFrame(y_pred)\n",
    "df_y_pred.to_csv(\"miqp_y__pred_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddd7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error is: 2.39199\n"
     ]
    }
   ],
   "source": [
    "y_pred = X_train@beta\n",
    "print(\"train error is: \"+ str(round(mean_squared_error(Y_train, y_pred),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f9ebc",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Use scikit learn to do 10-fold cross validation on the training set to pick lambda. Once you find \n",
    "the best value of lambda, fit a LASSO model to the entire training set using that value of lambda. \n",
    "With the betas you find in that LASSO model make a prediction of the y values in the test \n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcedc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff116a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('training_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66750099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining feature space and target variable\n",
    "X_train = np.array(train_df.iloc[0:,1:])\n",
    "Y_train = np.array(train_df['y'])\n",
    "X_test = np.array(test_df.iloc[0:,1:])\n",
    "Y_test = np.array(test_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "259e3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fitting on x train\n",
    "std_trans = StandardScaler()\n",
    "std_trans.fit(X_train)\n",
    "\n",
    "#transforming on X_train and X_test\n",
    "X_train_std = std_trans.transform(X_train)\n",
    "X_test_std = std_trans.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be793c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Lambda is : 0.08471942409934509\n",
      "Total non-zero features using Lasso: 18\n",
      "The value of MSE on the test data is: 2.35667\n",
      "The value of MSE on the train data is: 2.38644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fitting the lasso model to get the optimal lambda \n",
    "lasso_regression_cv = linear_model.LassoCV(cv=10).fit(X_train_std, Y_train)\n",
    "print('Optimal Lambda is :', lasso_regression_cv.alpha_)\n",
    "\n",
    "# calculating number of features\n",
    "print('Total non-zero features using Lasso:', (lasso_regression_cv.coef_ != 0).sum())\n",
    "\n",
    "#predicting value of y on the test data\n",
    "y_pred=lasso_regression_cv.predict(X_test_std)\n",
    "\n",
    "#calculating MSE on test data\n",
    "print('The value of MSE on the test data is:', round(mean_squared_error(Y_test, y_pred),5))\n",
    "\n",
    "#predicting value of y on the train data\n",
    "y_pred=lasso_regression_cv.predict(X_train_std)\n",
    "\n",
    "#calculating MSE on train data\n",
    "print('The value of MSE on the train data is:', round(mean_squared_error(Y_train, y_pred),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48926e54",
   "metadata": {},
   "source": [
    "For report purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15832e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the beta values for lasso\n",
    "beta_lasso=lasso_regression_cv.coef_\n",
    "df_beta_lasso = pd.DataFrame(beta_lasso)\n",
    "\n",
    "# for report purposes\n",
    "df_beta_lasso.to_csv(\"miqp_beta_lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99c44c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2762324862184158"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept from lasso\n",
    "intercept_lasso=lasso_regression_cv.intercept_\n",
    "intercept_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b03939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for report purposes\n",
    "#predicting value of y on the test data\n",
    "y_pred=lasso_regression_cv.predict(X_test_std)\n",
    "df_y_pred_lasso = pd.DataFrame(y_pred)\n",
    "df_y_pred_lasso.to_csv(\"y_pred_lasso.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6afe1e",
   "metadata": {},
   "source": [
    "Please note that all the charts and comparisons has been done in the Excel which is attached along with the submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d02c4a08a73a4fbd702ec45bd3651da6e987cfb739a67e8c96925f5fc77108dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
